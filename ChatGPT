ChatGPT

ChatGPT discussions are everywhere, with opinions regarding its existence ranging from it representing a new age of information, to the end of humanity, and everything in between. 
While ChatGPT and Artificial Intelligence are amazing in what they can do, they're really just iterations of the constantly-maturing computer learning space.  Having begun innocently in the early 1960s, the big paradigm shift occurred when "machine learning" was reborn with the modern benefit of previously unfathomable amounts of available data.
Machine Learning is differentiated from traditional computing in that computers are given vast amounts of information (called Training sets), and are tasked with detecting patterns in that data, which inform their predictions of similar data outcomes to which they've not yet been exposed. 
A common illustration of Machine Learning is patterns in housing prices, usually for a specific city or area. 
Very generally, the computer is fed various details (called Features) about a property, such as zip code, square footage, number of bedrooms, number of bathrooms, age of the house, front door color, etc, with a known sale price. 
The computer analyzes these Features, and figures out how important each feature is in determining the known sale price (called the Target), and stores these details as "Weights". Maybe the zip code carries a weight of 0.54836 while the front door color represents a weight of 0.000000000026 (paint is cheap!). Once these  patterns are Trained and Tested, the resulting algorithm is called a Model. If the Model works well, another set of house data can be presented to the computer without the sale price, and a reasonably accurate sale price will be returned.  
Deep Learning is similar, but differs in a couple of nuanced but important ways from Machine Learning. At a high level, it ingests information as more of a clump (image) or stream (text or speech) of data, and learns Features as an aggregation as opposed to pre-defined and delineated Features. Deep Learning uses Neurons, whose function mirrors our own brain neurons, where correct inputs are given more Weight, and (hopefully) incorrect ideas or inputs are discarded.  The determination of "good" vs "bad" inputs is a bit deep (ha!) for this post, but Back Propagation and Loss Functions are fascinating topics to explore if you're interested!
Getting back to ChatGPT, it is really nothing more than a very well trained Deep Learning text-speech model with a HUGE repository of stored conversation data.  That's not so scaryâ€¦or is it?
Thanks for reading!
